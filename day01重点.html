<html><head></head><body><div class="markdown-body"><h1>第一天</h1>

<h3>1.爬虫的概念</h3>

<ul>
<li>爬虫是模拟浏览器发送请求，获取响应

<h3>http和https区别</h3></li>
<li>https是经过安全加密后的操作,执行的效率比http要慢

<h3>爬虫的流程</h3></li>
<li>url&mdash;>发送请求，获取响应&mdash;>提取数据&mdash;》保存</li>
<li>发送请求，获取响应&mdash;>提取url</li>
</ul>


<h4>爬虫要根据当前url地址对应的响应为准 ，当前url地址的elements的内容和url的响应不一样</h4>

<h3>2.http常见的请求头</h3>

<ul>
<li>Host(主机的端口号)</li>
<li>Connettion (链接的类型)</li>
<li>Upgrade-Insecure-Requests (http升级为https的请求)</li>
<li><strong> User-Agent</strong>   (浏览器的名称,含有请求客户端的设备等基本的信息)</li>
<li>Accept  (传输文件的类型)</li>
<li>Referer (页面的跳转处)</li>
<li>Accept-Encoding(文件的编码格式)</li>
<li><strong> Cookie </strong> (模仿客户端请求比较重要)</li>
<li>x-requested-with :XMLHttpRequest(是Ajax异步的请求)</li>
</ul>


<h3>3.页面上的数据在哪里</h3>

<ul>
<li>当前url地址对应的响应中</li>
<li>其他的url地址对应的响应中

<ul>
<li>比如ajax请求中</li>
</ul>
</li>
<li>js生成的

<ul>
<li>部分数据在响应中</li>
<li>全部通过js生成</li>
</ul>
</li>
</ul>


<h3>4.requests中解决编解码的方法-这三种可以解决所有的解码方式</h3>

<ul>
<li>requests.get/post发送请求后的返回值response</li>
<li>response.content.decode()  # 建议使用这种,默认使用utf8解码,90%网站用这种->获取到的是二进制的bytes类型的数据,用decode()进行的解码</li>
<li>response.content.decode(&ldquo;gbk&rdquo;)  # gbk解码的方式</li>
<li>response.text</li>
</ul>


<h3>小知识</h3>

<ul>
<li>读取和保存文件
<code>
with open("./image.jpg", "wb") as f:
   f.write(二进制的文件)  
</code>
说明:<br/>
1.with open 是打开一个文件,<br/>
2.第一个参数若是打开一个文件则是文件的路径+文件名;<br/>
若是写入一个文件就是文件的路径+具体文件的名称+后缀,什么类型就保存什么格式->    图片就是图片的类型,pdf就是pdf , 视频就是mp4等;<br/>
3.第二个参数不写默认是读取的文件的方式;默认是按照字符串的类型;<br/>
&ldquo;w"是写入的方式, "r"是读取的方式-> 都是按照str格式来写入或读取;<br/>
"wb"是按照二进制的方式写入,  "rb"是按照二进制的方式读取;<br/>
4.f是文件响应的对象; 若是按照str方式写入可以f.write("xx&rdquo;) 直接写入内容<br/>
若是按照二进制写入的时候需要写入的是二进制的变量;
5.f.read() 是读取文件的内容,若是二进制则可以直接读取为二进制,保存到指定的变量中;<br/>
若是 str 则读取的是字符串的内容;</li>
<li><p>当写入文件会报错,一般添加参数endcoding=&ldquo;utf-8"进行解码就可以;</p></li>
<li><p>字符串格式化的另外一种方式 format<br/>
<code>
"传智{}播{}课{}".format({"a":2}, 2,"好")  
输出-&gt;"传智{"a": 2}播2课好"
</code></p></li>
</ul>
</div></body></html>